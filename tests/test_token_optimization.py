"""
Tokenè®¡ç®—ä¼˜åŒ–æµ‹è¯•
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from copilot.utils.token_calculator import TokenCalculator, TokenUsage


def test_token_calculator():
    """æµ‹è¯•Tokenè®¡ç®—å™¨"""
    print("ğŸ§ª æµ‹è¯•Tokenè®¡ç®—å™¨")
    
    # æµ‹è¯•åŸºæœ¬tokenä¼°ç®—
    text = "Hello, this is a test message. ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯ã€‚"
    tokens = TokenCalculator.estimate_tokens(text, "gpt-4")
    print(f"ğŸ“ æ–‡æœ¬: {text}")
    print(f"ğŸ”¢ ä¼°ç®—tokens: {tokens}")
    
    # æµ‹è¯•å®Œæ•´ç”¨æ³•è®¡ç®—
    prompt = "è¯·å¸®æˆ‘å†™ä¸€ä¸ªPythonå‡½æ•°"
    completion = "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å†™ä¸€ä¸ªPythonå‡½æ•°ï¼š\n\ndef example_function():\n    return 'Hello World'"
    
    usage = TokenCalculator.calculate_usage(prompt, completion, "deepseek")
    print(f"\nğŸ’¬ å¯¹è¯tokenç»Ÿè®¡:")
    print(f"   ç”¨æˆ·è¾“å…¥: {usage.prompt_tokens} tokens")
    print(f"   æ¨¡å‹å›å¤: {usage.completion_tokens} tokens") 
    print(f"   æ€»è®¡: {usage.total_tokens} tokens")
    
    # æµ‹è¯•å®‰å…¨æå–
    test_data = {"prompt_tokens": 15, "completion_tokens": 25, "total_tokens": 40}
    safe_usage = TokenCalculator.safe_extract_tokens(test_data)
    print(f"\nğŸ›¡ï¸ å®‰å…¨æå–æµ‹è¯•: {safe_usage.to_dict()}")
    
    # æµ‹è¯•é”™è¯¯æƒ…å†µ
    invalid_data = None
    safe_usage_none = TokenCalculator.safe_extract_tokens(invalid_data)
    print(f"ğŸš« Noneæ•°æ®å¤„ç†: {safe_usage_none.to_dict()}")
    
    print("âœ… Tokenè®¡ç®—å™¨æµ‹è¯•å®Œæˆï¼")


def test_model_mapping():
    """æµ‹è¯•æ¨¡å‹æ˜ å°„"""
    print("\nğŸ—ºï¸ æµ‹è¯•æ¨¡å‹æ˜ å°„")
    
    test_cases = [
        ("openai", "gpt-4-turbo"),
        ("deepseek", "deepseek-chat"),
        ("claude", "claude-3-sonnet"),
        ("qwen", "qwen-max"),
        ("unknown", "unknown-model")
    ]
    
    for provider, model in test_cases:
        key = TokenCalculator.get_model_key(provider, model)
        print(f"ğŸ”‘ {provider}/{model} -> {key}")
    
    print("âœ… æ¨¡å‹æ˜ å°„æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_token_calculator()
    test_model_mapping()
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
