#!/usr/bin/env python3
"""
æµ‹è¯•å·¥å…·ç»“æœé›†æˆå’Œæ¶ˆæ¯é¡ºåºä¿®å¤
"""

import asyncio
import json
import os
import sys
from datetime import datetime, UTC
from typing import Any, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from copilot.core.stream_notifier import StreamNotifier
from copilot.core.mcp_tool_wrapper import MCPToolWrapper
from copilot.model.chat_model import ToolExecutionStatus
from copilot.core.chat_stream_handler import ChatStreamHandler


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ç¯å¢ƒå˜é‡:", os.getenv("ENV", "dev"))
    print("ğŸ¯ å¼€å§‹æµ‹è¯•å·¥å…·ç»“æœé›†æˆå’Œæ¶ˆæ¯é¡ºåºä¿®å¤")
    print("=" * 60)

    # æµ‹è¯•1ï¼šå·¥å…·æ‰§è¡ŒçŠ¶æ€çš„resultå­—æ®µæ ¼å¼
    print("ğŸ§ª æµ‹è¯•å·¥å…·æ‰§è¡ŒçŠ¶æ€çš„resultå­—æ®µæ ¼å¼")
    print()

    test_cases = [
        {"data": {"code": 0, "message": "success"}, "type": "dict"},
        {"data": "String result", "type": "str"},
        {"data": [1, 2, 3, "test"], "type": "list"},
        {"data": 42, "type": "int"},
        {"data": None, "type": "NoneType"},
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"æµ‹è¯•ç»“æœæ ¼å¼ {i}: {test_case['type']}")

        # åˆ›å»ºå·¥å…·æ‰§è¡ŒçŠ¶æ€
        status = ToolExecutionStatus(
            request_id="test-request-id",
            tool_name="pubmed_pubmed_search_journal",
            status="completed",
            result=test_case["data"],  # ç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
            error=None,
            progress=None,
        )

        print(f"  æ¶ˆæ¯ç±»å‹: tool_execution_status")
        print(f"  å·¥å…·åç§°: {status.tool_name}")
        print(f"  çŠ¶æ€: {status.status}")
        print(f"  åŸå§‹ç»“æœç±»å‹: {type(test_case['data']).__name__}")
        print(f"  resultå­—æ®µç±»å‹: {type(status.result).__name__}")

        # éªŒè¯ç±»å‹ä¿æŒä¸å˜
        assert type(status.result) == type(test_case["data"]), f"ç±»å‹ä¸åŒ¹é…: {type(status.result)} vs {type(test_case['data'])}"
        print("  âœ… åŸå§‹å¯¹è±¡ç±»å‹ä¿æŒä¸å˜")

        # éªŒè¯å€¼ç›¸ç­‰
        assert status.result == test_case["data"], f"å€¼ä¸åŒ¹é…: {status.result} vs {test_case['data']}"
        print("  âœ… å€¼å®Œå…¨ä¸€è‡´")
        print()

    # æµ‹è¯•2ï¼šå‚æ•°æå–åŠŸèƒ½
    print("ğŸ§ª æµ‹è¯•å‚æ•°æå–åŠŸèƒ½")
    print()

    # æµ‹è¯•ä¸åŒç±»å‹çš„å‚æ•°
    test_args_cases = [
        {"args": ({"query": "machine learning", "limit": 10, "filter": "recent"},), "description": "å­—å…¸å‚æ•°"},
        {"args": ("simple string query",), "description": "å­—ç¬¦ä¸²å‚æ•°"},
        {"args": ({"query": "x" * 250},), "description": "é•¿å­—ç¬¦ä¸²å‚æ•°ï¼ˆæµ‹è¯•æˆªæ–­ï¼‰"},  # é•¿å­—ç¬¦ä¸²æµ‹è¯•æˆªæ–­
        {"args": (), "description": "ç©ºå‚æ•°"},
        {"args": ({"key1": "value1"}, "extra_param"), "description": "å¤šä¸ªå‚æ•°"},
    ]

    for i, test_case in enumerate(test_args_cases, 1):
        print(f"å‚æ•°æå–æµ‹è¯• {i}: {test_case['description']}")

        # ä½¿ç”¨StreamNotifieræå–å‚æ•°
        extracted_params = StreamNotifier.extract_tool_parameters(test_case["args"])

        print(f"  è¾“å…¥å‚æ•°: {test_case['args']}")
        print(f"  æå–ç»“æœ: {extracted_params}")
        print(f"  æå–ç»“æœç±»å‹: {type(extracted_params).__name__}")

        # éªŒè¯æå–ç»“æœæ˜¯å­—å…¸
        assert isinstance(extracted_params, dict), f"æå–ç»“æœåº”è¯¥æ˜¯å­—å…¸ï¼Œä½†å¾—åˆ°: {type(extracted_params)}"
        print("  âœ… æå–ç»“æœæ˜¯å­—å…¸æ ¼å¼")

        # éªŒè¯ç‰¹å®šæƒ…å†µ
        if test_case["args"] and len(test_case["args"]) == 1 and isinstance(test_case["args"][0], dict):
            # å•ä¸ªå­—å…¸å‚æ•°åº”è¯¥è¢«æ­£ç¡®æå–
            original_dict = test_case["args"][0]
            if any(len(str(v)) > 200 for v in original_dict.values()):
                print("  âœ… é•¿å­—ç¬¦ä¸²è¢«æ­£ç¡®æˆªæ–­")
            else:
                for key in original_dict:
                    assert key in extracted_params, f"å­—å…¸é”® {key} æœªè¢«æå–"
                print("  âœ… å­—å…¸å‚æ•°è¢«æ­£ç¡®æå–")
        elif test_case["args"]:
            # å¤šä¸ªå‚æ•°æˆ–éå­—å…¸å‚æ•°åº”è¯¥è¢«åŒ…è£…åœ¨ args ä¸­
            assert "args" in extracted_params, "å¤šä¸ªå‚æ•°æˆ–éå­—å…¸å‚æ•°åº”è¯¥è¢«åŒ…è£…åœ¨ args ä¸­"
            print("  âœ… å¤šä¸ªå‚æ•°æˆ–éå­—å…¸å‚æ•°è¢«æ­£ç¡®åŒ…è£…")
        else:
            # ç©ºå‚æ•°åº”è¯¥è¿”å›ç©ºå­—å…¸
            assert extracted_params == {}, f"ç©ºå‚æ•°åº”è¯¥è¿”å›ç©ºå­—å…¸ï¼Œä½†å¾—åˆ°: {extracted_params}"
            print("  âœ… ç©ºå‚æ•°è¿”å›ç©ºå­—å…¸")
        print()

    # æµ‹è¯•3ï¼š_format_for_aiæ–¹æ³•
    print("ğŸ§ª æµ‹è¯•_format_for_aiæ–¹æ³•æ ¼å¼åŒ–ç»“æœ")
    test_data = {"code": 0, "data": [{"title": "Test Article", "authors": ["Author1", "Author2"]}]}

    # ä½¿ç”¨_format_for_aiæ–¹æ³•æ ¼å¼åŒ–
    formatted_result = MCPToolWrapper._format_for_ai("pubmed_pubmed_search_journal", test_data)

    print(f"æ ¼å¼åŒ–ç»“æœé•¿åº¦: {len(formatted_result)}")
    print(f"æ˜¯å¦åŒ…å«å‰ç¼€: {'å·¥å…·' in formatted_result and 'æ‰§è¡Œç»“æœ' in formatted_result}")

    # éªŒè¯ä¸åŒ…å«å‰ç¼€
    assert "å·¥å…·" not in formatted_result or "æ‰§è¡Œç»“æœ" not in formatted_result, "æ ¼å¼åŒ–ç»“æœä¸åº”åŒ…å«å‰ç¼€"
    print("âœ… _format_for_aiä¸åŒ…å«å‰ç¼€")

    # éªŒè¯æ˜¯æœ‰æ•ˆçš„JSON
    try:
        json.loads(formatted_result)
        print("âœ… æ ¼å¼åŒ–ç»“æœæ˜¯æœ‰æ•ˆçš„JSON")
    except json.JSONDecodeError:
        print("âŒ æ ¼å¼åŒ–ç»“æœä¸æ˜¯æœ‰æ•ˆçš„JSON")

    print()

    # æµ‹è¯•4ï¼šå®Œæ•´çš„å·¥å…·æ‰§è¡Œæµç¨‹æ¨¡æ‹Ÿ
    print("ğŸ§ª æ¨¡æ‹Ÿå®Œæ•´çš„å·¥å…·æ‰§è¡Œæµç¨‹")

    session_id = "test-session-flow"
    tool_name = "pubmed_pubmed_search_journal"
    test_parameters = {"query": "AI research", "limit": 5}
    test_result = {"code": 0, "data": ["result1", "result2"]}

    # æ¸…ç©ºæ¶ˆæ¯é˜Ÿåˆ—
    StreamNotifier._pending_messages[session_id] = []

    # 1. å‘é€æƒé™è¯·æ±‚
    request_id = await StreamNotifier.send_tool_permission_request(
        session_id=session_id, tool_name=tool_name, parameters=test_parameters, risk_level="medium"
    )

    # 2. å‘é€ç­‰å¾…çŠ¶æ€
    await StreamNotifier.send_tool_execution_status(session_id=session_id, request_id=request_id, tool_name=tool_name, status="waiting")

    # 3. å‘é€æ‰§è¡ŒçŠ¶æ€
    await StreamNotifier.send_tool_execution_status(session_id=session_id, request_id=request_id, tool_name=tool_name, status="executing")

    # 4. å‘é€å®ŒæˆçŠ¶æ€ï¼ˆå¸¦ç»“æœï¼‰
    await StreamNotifier.send_tool_execution_status(
        session_id=session_id, request_id=request_id, tool_name=tool_name, status="completed", result=test_result
    )

    # è·å–æ‰€æœ‰æ¶ˆæ¯
    messages = StreamNotifier.get_pending_messages(session_id)

    print(f"æ€»æ¶ˆæ¯æ•°: {len(messages)}")
    print("æ¶ˆæ¯é¡ºåº:")

    expected_types = ["tool_permission_request", "tool_execution_status", "tool_execution_status", "tool_execution_status"]
    expected_statuses = [None, "waiting", "executing", "completed"]

    for i, message in enumerate(messages, 1):
        message_type = message.type
        print(f"  {i}. {message_type.replace('_', ' ').title()}")

        if message_type == "tool_permission_request":
            # æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®
            assert message.data.parameters == test_parameters, f"æƒé™è¯·æ±‚å‚æ•°ä¸åŒ¹é…: {message.data.parameters} vs {test_parameters}"
            print(f"     å‚æ•°: {message.data.parameters}")

        elif message_type == "tool_execution_status":
            print(f"     çŠ¶æ€: {message.data.status}")
            if message.data.status == "completed":
                print(f"     ç»“æœç±»å‹: {type(message.data.result).__name__}")
                # éªŒè¯ç»“æœæ˜¯åŸå§‹å¯¹è±¡
                assert message.data.result == test_result, f"å®ŒæˆçŠ¶æ€ç»“æœä¸åŒ¹é…: {message.data.result} vs {test_result}"
                assert type(message.data.result) == type(test_result), f"å®ŒæˆçŠ¶æ€ç»“æœç±»å‹ä¸åŒ¹é…: {type(message.data.result)} vs {type(test_result)}"

    # éªŒè¯æ¶ˆæ¯é¡ºåºå’Œç±»å‹
    assert len(messages) == 4, f"åº”è¯¥æœ‰4æ¡æ¶ˆæ¯ï¼Œä½†å¾—åˆ°: {len(messages)}"
    for i, (message, expected_type, expected_status) in enumerate(zip(messages, expected_types, expected_statuses)):
        assert message.type == expected_type, f"æ¶ˆæ¯{i+1}ç±»å‹é”™è¯¯: {message.type} vs {expected_type}"
        if expected_status:
            assert message.data.status == expected_status, f"æ¶ˆæ¯{i+1}çŠ¶æ€é”™è¯¯: {message.data.status} vs {expected_status}"

    print("âœ… æ¶ˆæ¯é¡ºåºæ­£ç¡®")
    print()

    # æµ‹è¯•5ï¼šéªŒè¯å·¥å…·è¿”å›æ ¼å¼ï¼ˆäºŒå…ƒç»„æ»¡è¶³langchain-mcp-adaptersè¦æ±‚ï¼‰
    print("ğŸ§ª éªŒè¯å·¥å…·è¿”å›æ ¼å¼")

    # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œï¼Œåº”è¯¥è¿”å›äºŒå…ƒç»„æ ¼å¼ä»¥æ»¡è¶³langchain-mcp-adaptersè¦æ±‚
    mock_tool_result = test_result
    formatted_for_ai = MCPToolWrapper._format_for_ai(tool_name, mock_tool_result)

    print(f"_format_for_aiç»“æœç±»å‹: {type(formatted_for_ai).__name__}")
    print(f"_format_for_aiç»“æœé•¿åº¦: {len(formatted_for_ai)}")
    print(f"æ˜¯å¦ä¸ºå­—ç¬¦ä¸²: {isinstance(formatted_for_ai, str)}")

    # éªŒè¯_format_for_aiè¿”å›çš„æ˜¯å­—ç¬¦ä¸²
    assert isinstance(formatted_for_ai, str), f"_format_for_aiåº”è¯¥è¿”å›å­—ç¬¦ä¸²ï¼Œä½†å¾—åˆ°: {type(formatted_for_ai)}"
    print("âœ… _format_for_aiè¿”å›å­—ç¬¦ä¸²æ ¼å¼")

    # éªŒè¯å­—ç¬¦ä¸²ä¸æ˜¯å…ƒç»„çš„å­—ç¬¦ä¸²è¡¨ç¤º
    assert not formatted_for_ai.startswith("("), "æ ¼å¼åŒ–ç»“æœä¸åº”è¯¥æ˜¯å…ƒç»„çš„å­—ç¬¦ä¸²è¡¨ç¤º"
    assert not formatted_for_ai.endswith(")"), "æ ¼å¼åŒ–ç»“æœä¸åº”è¯¥æ˜¯å…ƒç»„çš„å­—ç¬¦ä¸²è¡¨ç¤º"
    print("âœ… æ ¼å¼åŒ–ç»“æœä¸æ˜¯å…ƒç»„æ ¼å¼")

    # æ¨¡æ‹Ÿå®Œæ•´çš„å·¥å…·è¿”å›ï¼ˆåº”è¯¥æ˜¯äºŒå…ƒç»„ï¼‰
    tool_tuple_result = (formatted_for_ai, mock_tool_result)
    print(f"å®Œæ•´å·¥å…·è¿”å›ç±»å‹: {type(tool_tuple_result).__name__}")
    print(f"å…ƒç»„ç¬¬ä¸€é¡¹ç±»å‹: {type(tool_tuple_result[0]).__name__}")
    print(f"å…ƒç»„ç¬¬äºŒé¡¹ç±»å‹: {type(tool_tuple_result[1]).__name__}")

    # éªŒè¯å·¥å…·è¿”å›æ˜¯äºŒå…ƒç»„
    assert isinstance(tool_tuple_result, tuple), f"å·¥å…·åº”è¯¥è¿”å›å…ƒç»„ï¼Œä½†å¾—åˆ°: {type(tool_tuple_result)}"
    assert len(tool_tuple_result) == 2, f"å·¥å…·åº”è¯¥è¿”å›äºŒå…ƒç»„ï¼Œä½†å¾—åˆ°é•¿åº¦: {len(tool_tuple_result)}"
    print("âœ… å·¥å…·è¿”å›äºŒå…ƒç»„æ ¼å¼ä»¥æ»¡è¶³langchain-mcp-adaptersè¦æ±‚")

    print()

    # æµ‹è¯•6ï¼šéªŒè¯èŠå¤©æµå¤„ç†å™¨æ¶ˆæ¯è¿‡æ»¤
    print("ğŸ§ª éªŒè¯èŠå¤©æµå¤„ç†å™¨æ¶ˆæ¯è¿‡æ»¤")

    # åˆ›å»ºæ¨¡æ‹Ÿæ¶ˆæ¯ç±»
    class MockAIMessage:
        def __init__(self, content):
            self.content = content
            self.role = "assistant"
            self.type = "ai"

    class MockToolMessage:
        def __init__(self, content, tool_call_id=None):
            self.content = content
            self.role = "tool"
            self.type = "tool"
            if tool_call_id:
                self.tool_call_id = tool_call_id

    class MockHumanMessage:
        def __init__(self, content):
            self.content = content
            self.role = "user"
            self.type = "human"

    class MockAIMessageChunk:
        def __init__(self, content):
            self.content = content
            self.role = "assistant"
            self.type = "ai"

    # åˆ›å»ºèŠå¤©æµå¤„ç†å™¨å®ä¾‹
    handler = ChatStreamHandler(None)

    # æµ‹è¯•ä¸åŒç±»å‹çš„æ¶ˆæ¯
    test_messages = [
        {"message": MockAIMessage("Hello, how can I help?"), "description": "AIåŠ©æ‰‹æ¶ˆæ¯", "should_output": True},
        {"message": MockHumanMessage("User question here"), "description": "ç”¨æˆ·æ¶ˆæ¯", "should_output": False},
        {"message": MockToolMessage('{"code": 0, "data": []}'), "description": "å·¥å…·æ¶ˆæ¯", "should_output": False},
        {
            "message": MockToolMessage("Tool result content", tool_call_id="call-123"),
            "description": "å¸¦tool_call_idçš„å·¥å…·æ¶ˆæ¯",
            "should_output": False,
        },
        {"message": MockAIMessageChunk("AI response based on tool"), "description": "AIæ¶ˆæ¯å—", "should_output": True},
    ]

    for i, test_case in enumerate(test_messages, 1):
        message = test_case["message"]
        description = test_case["description"]
        should_output = test_case["should_output"]

        # æµ‹è¯•æ¶ˆæ¯åˆ¤æ–­
        is_ai_message = handler._is_ai_message(message)

        print(f"æµ‹è¯•æ¶ˆæ¯ {i}: {description}")
        print(f"  æ¶ˆæ¯ç±»å‹: {type(message).__name__}")
        print(f"  æ¶ˆæ¯è§’è‰²: {getattr(message, 'role', 'None')}")
        print(f"  æ˜¯å¦AIæ¶ˆæ¯: {is_ai_message}")
        print(f"  é¢„æœŸè¾“å‡º: {should_output}")

        if is_ai_message == should_output:
            print("  âœ… æ¶ˆæ¯è¿‡æ»¤åˆ¤æ–­æ­£ç¡®")
        else:
            print("  âŒ æ¶ˆæ¯è¿‡æ»¤åˆ¤æ–­é”™è¯¯")
            print(f"     æœŸæœ›: {should_output}, å®é™…: {is_ai_message}")
        print()

    print("âœ… èŠå¤©æµæ¶ˆæ¯è¿‡æ»¤æµ‹è¯•å®Œæˆ")
    print()

    print("=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
