"""
èŠå¤©æµå¤„ç†å™¨ - å¤„ç†æµå¼èŠå¤©è¾“å‡ºå’Œæƒé™ç¡®è®¤
"""

from typing import AsyncGenerator, Dict, Optional

from copilot.utils.logger import logger
from copilot.config.settings import conf

# from copilot.config.settings import Config, ChatConfig


# ä¸´æ—¶ç¡¬ç¼–ç é…ç½®ï¼Œåç»­å¯ä»¥ä»é…ç½®æ–‡ä»¶è¯»å–
class ChatConfig:
    """èŠå¤©é…ç½®"""

    ENABLE_AI_THINKING_CLASSIFICATION = True  # æ˜¯å¦å¯ç”¨AIæ€è€ƒå’Œå›ç­”åˆ†ç±»
    THINKING_EMOJI = "ğŸ¤”"  # æ€è€ƒé˜¶æ®µçš„è¡¨æƒ…ç¬¦å·
    RESPONSE_EMOJI = "ğŸ’¬"  # å›ç­”é˜¶æ®µçš„è¡¨æƒ…ç¬¦å·
    THINKING_PREFIX = "**AIæ€è€ƒä¸­**ï¼š"  # æ€è€ƒé˜¶æ®µçš„å‰ç¼€
    RESPONSE_PREFIX = "**AIå›ç­”**ï¼š"  # å›ç­”é˜¶æ®µçš„å‰ç¼€

    # æ€è€ƒæ¨¡å¼çš„å…³é”®è¯ - åŒ…æ‹¬å„ç§æ€ç»´è¿‡ç¨‹
    THINKING_KEYWORDS_ZH = [
        # è¡ŒåŠ¨è§„åˆ’ç±»
        "æˆ‘éœ€è¦",
        "è®©æˆ‘",
        "é¦–å…ˆ",
        "æˆ‘åº”è¯¥",
        "ä¸ºäº†å›ç­”",
        "ä¸ºäº†è·å–",
        "æˆ‘æ¥",
        "ç°åœ¨è®©æˆ‘",
        "æ¥ä¸‹æ¥æˆ‘",
        "æˆ‘æƒ³",
        "æˆ‘ä¼š",
        "æˆ‘å°†",
        "æˆ‘è¦",
        "æˆ‘å…ˆ",
        "è®©æˆ‘ä»¬",
        "æˆ‘ä»¬éœ€è¦",
        "æˆ‘ä»¬æ¥",
        "æˆ‘ä»¬å…ˆ",
        "æˆ‘ä»¬åº”è¯¥",
        # é—®é¢˜åˆ†æç±»
        "è¿™ä¸ªé—®é¢˜",
        "è¿™é‡Œéœ€è¦è€ƒè™‘",
        "æˆ‘ä»¬æ¥åˆ†æ",
        "è®©æˆ‘åˆ†æ",
        "åˆ†æä¸€ä¸‹",
        "è€ƒè™‘åˆ°",
        "éœ€è¦æ³¨æ„",
        "å€¼å¾—æ€è€ƒ",
        "å…³é”®åœ¨äº",
        "é—®é¢˜çš„æ ¸å¿ƒ",
        # æ¨ç†æ€è€ƒç±»
        "ä»é€»è¾‘ä¸Š",
        "æ¨ç†è¿‡ç¨‹",
        "å› æ­¤å¯ä»¥",
        "ç”±æ­¤å¯è§",
        "ç»¼åˆè€ƒè™‘",
        "æƒè¡¡åˆ©å¼Š",
        "æ¯”è¾ƒåˆ†æ",
        "æ·±å…¥æ€è€ƒ",
        "ä»”ç»†è€ƒè™‘",
        "è¿›ä¸€æ­¥åˆ†æ",
        # æ–¹æ¡ˆè§„åˆ’ç±»
        "åˆ¶å®šç­–ç•¥",
        "è§„åˆ’æ–¹æ¡ˆ",
        "è®¾è®¡æ€è·¯",
        "è§£å†³æ–¹æ¡ˆ",
        "å®ç°æ­¥éª¤",
        "å…·ä½“åšæ³•",
        "é‡‡ç”¨æ–¹æ³•",
        "é€‰æ‹©ç­–ç•¥"
    ]

    THINKING_KEYWORDS_EN = [
        # Action planning
        "I need to",
        "Let me",
        "I should",
        "To answer",
        "In order to",
        "I'll",
        "I will",
        "I want to",
        "I'm going to",
        "Let's",
        "We need to",
        "We should",
        "First, I'll",
        "Now I'll",
        # Problem analysis
        "This problem",
        "We need to consider",
        "Let me analyze",
        "Analyzing this",
        "Considering",
        "It's important to note",
        "The key is",
        "The core issue",
        "Worth thinking about",
        # Reasoning process
        "Logically speaking",
        "From a logical perspective",
        "Therefore",
        "Thus we can",
        "Given that",
        "Weighing the options",
        "Comparing",
        "Thinking deeper",
        "Upon reflection",
        "Further analysis shows"
    ]

    # å›ç­”æ¨¡å¼çš„å…³é”®è¯
    RESPONSE_KEYWORDS_ZH = [
        "æ ¹æ®æŸ¥è¯¢ç»“æœ",
        "åŸºäºæœç´¢ç»“æœ",
        "æŸ¥è¯¢ç»“æœæ˜¾ç¤º",
        "æ ¹æ®å·¥å…·è¿”å›",
        "åŸºäºè·å–çš„ä¿¡æ¯",
        "ä»ç»“æœä¸­å¯ä»¥çœ‹åˆ°",
        "æœç´¢ç»“æœè¡¨æ˜",
        "é€šè¿‡æŸ¥è¯¢å‘ç°",
        "æ ¹æ®åˆ†æç»“æœ",
        "æŸ¥è¯¢åˆ°çš„ä¿¡æ¯",
        "æœç´¢å¾—åˆ°",
        "è·å–çš„æ•°æ®æ˜¾ç¤º",
    ]

    RESPONSE_KEYWORDS_EN = [
        "Based on the results",
        "According to the search",
        "The results show",
        "From the search results",
        "The query returned",
        "Based on the data",
        "According to the analysis",
        "The search revealed",
        "Results indicate",
    ]


class ChatStreamHandler:
    """èŠå¤©æµå¤„ç†å™¨ - è´Ÿè´£å¤„ç†æµå¼è¾“å‡ºå’Œæƒé™ç¡®è®¤æµç¨‹"""

    def __init__(self, graph):
        """
        åˆå§‹åŒ–èŠå¤©æµå¤„ç†å™¨

        Args:
            graph: LangGraphå®ä¾‹
        """
        self.graph = graph

    async def handle_stream_with_permission(self, inputs: Dict, config: Dict, session_id: Optional[str]) -> AsyncGenerator[str, None]:
        """å¸¦æƒé™å¤„ç†çš„æµå¼èŠå¤©æ–¹æ³•"""
        try:
            from copilot.core.agent_state_manager import AgentExecutionState, agent_state_manager

            # è·å–æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆä¸é‡å¤è®¾ç½®çŠ¶æ€ï¼Œå› ä¸ºagent.pyä¸­å·²ç»è®¾ç½®äº†ï¼‰
            context = None
            if session_id:
                context = agent_state_manager.get_execution_context(session_id)
                # å¦‚æœæ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜ï¼Œä½†ä¸åœ¨è¿™é‡Œåˆ›å»ºï¼Œå› ä¸ºåº”è¯¥åœ¨agent.pyä¸­åˆ›å»º
                if not context:
                    logger.warning(f"No execution context found for session {session_id} in ChatStreamHandler")
                    context = agent_state_manager.create_execution_context(session_id)
                    context.update_state(AgentExecutionState.RUNNING)

            # æµå¼å¤„ç†èŠå¤©
            has_content = False
            permission_handled = False

            async for chunk in self._stream_internal(inputs, config):
                has_content = True

                # æ£€æŸ¥æ˜¯å¦é‡åˆ°æƒé™ç¡®è®¤è¯·æ±‚
                if "ğŸ”’ ç­‰å¾…ç”¨æˆ·ç¡®è®¤æ‰§è¡Œå·¥å…·:" in str(chunk):
                    yield chunk

                    # å¦‚æœæœ‰session_idï¼Œç­‰å¾…æƒé™ç¡®è®¤
                    if session_id and not permission_handled:
                        permission_handled = True
                        context = agent_state_manager.get_execution_context(session_id)
                        if context and context.state == AgentExecutionState.WAITING_PERMISSION:
                            yield "\n\nâ³ è¯·åœ¨èŠå¤©ç•Œé¢ä¸­ç¡®è®¤æ˜¯å¦å…è®¸æ‰§è¡Œæ­¤å·¥å…·...\n"

                            # ç­‰å¾…ç”¨æˆ·æƒé™ç¡®è®¤
                            permission_granted = await agent_state_manager.wait_for_permission(session_id, timeout=30)

                            if permission_granted:
                                yield "âœ… æƒé™å·²ç¡®è®¤ï¼Œç»§ç»­æ‰§è¡Œ...\n"
                                # ç»§ç»­æ‰§è¡Œ - è¿™é‡Œå¯èƒ½éœ€è¦é‡æ–°è°ƒç”¨Agentæˆ–æ¢å¤æ‰§è¡Œ
                                # ç”±äºæƒé™ç¡®è®¤åå·¥å…·å·²ç»åœ¨å›è°ƒä¸­æ‰§è¡Œï¼Œè¿™é‡Œä¸»è¦æ˜¯çŠ¶æ€åŒæ­¥
                                context.update_state(AgentExecutionState.COMPLETED)
                            else:
                                yield "âŒ æƒé™è¢«æ‹’ç»æˆ–è¶…æ—¶ï¼Œæ‰§è¡Œå·²åœæ­¢ã€‚\n"
                                context.update_state(AgentExecutionState.PAUSED)
                                break
                else:
                    # ç›´æ¥è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼Œä¸å†éœ€è¦è¿‡æ»¤é€»è¾‘
                    yield chunk

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿æ‰§è¡ŒçŠ¶æ€æ­£ç¡®ç»“æŸ
            if session_id and context:
                if has_content:
                    # å¦‚æœæ²¡æœ‰å¤„ç†æƒé™ç¡®è®¤ï¼Œè¯´æ˜æ²¡æœ‰å·¥å…·éœ€è¦æƒé™ï¼Œç›´æ¥å®Œæˆ
                    if not permission_handled:
                        context.update_state(AgentExecutionState.COMPLETED)
                        logger.info(f"Chat completed without tool permission requests for session: {session_id}")
                else:
                    # å¦‚æœæ²¡æœ‰è¾“å‡ºå†…å®¹ï¼Œå¯èƒ½æ˜¯é”™è¯¯çŠ¶æ€
                    context.update_state(AgentExecutionState.IDLE)
                    logger.info(f"Chat completed with no content for session: {session_id}")

        except Exception as e:
            logger.error(f"Error in chat_stream_with_permission_handling: {str(e)}")

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¼‚å¸¸æ—¶ä¹Ÿè¦æ›´æ–°çŠ¶æ€
            if session_id:
                context = agent_state_manager.get_execution_context(session_id)
                if context:
                    context.update_state(AgentExecutionState.ERROR, error=str(e))

            yield f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"

    async def _stream_internal(self, inputs: Dict, config: Dict) -> AsyncGenerator[str, None]:
        """å†…éƒ¨æµå¼èŠå¤©æ–¹æ³• - åŒºåˆ†AIæ€è€ƒå’Œæ­£å¼å›ç­”"""
        try:
            # å°è¯•ä½¿ç”¨æµå¼è¾“å‡º
            async for chunk in self.graph.astream(inputs, config=config, stream_mode="messages"):
                if chunk and len(chunk) >= 2:
                    message_chunk, _ = chunk
                    if hasattr(message_chunk, "content") and message_chunk.content:
                        # åªè¾“å‡ºAIåŠ©æ‰‹çš„æ¶ˆæ¯ï¼Œè¿‡æ»¤æ‰å·¥å…·æ¶ˆæ¯
                        if self._is_ai_message(message_chunk):
                            content = str(message_chunk.content)

                            # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ï¼ŒåŒºåˆ†æ€è€ƒå’Œå›ç­”
                            message_type = self._classify_ai_message(message_chunk)

                            if message_type == "thinking":
                                # æ€è€ƒé˜¶æ®µ - æ·»åŠ æ€è€ƒæ ‡è¯†
                                if ChatConfig.ENABLE_AI_THINKING_CLASSIFICATION:
                                    yield f"{ChatConfig.THINKING_EMOJI} {ChatConfig.THINKING_PREFIX}{content}"
                                else:
                                    yield content
                            elif message_type == "response":
                                # æ­£å¼å›ç­”é˜¶æ®µ - æ·»åŠ å›ç­”æ ‡è¯†
                                if ChatConfig.ENABLE_AI_THINKING_CLASSIFICATION:
                                    yield f"{ChatConfig.RESPONSE_EMOJI} {ChatConfig.RESPONSE_PREFIX}{content}"
                                else:
                                    yield content
                            else:
                                # é»˜è®¤è¾“å‡º
                                yield content
            return
        except Exception as e:
            logger.warning(f"Streaming failed: {str(e)}, falling back to chunk mode")

        # å›é€€åˆ°åˆ†å—æ¨¡å¼
        try:
            async for chunk in self.graph.astream(inputs, config=config, stream_mode="updates"):
                if "agent" in chunk and "messages" in chunk["agent"]:
                    for msg in chunk["agent"]["messages"]:
                        if hasattr(msg, "content") and msg.content:
                            # åªè¾“å‡ºAIåŠ©æ‰‹çš„æ¶ˆæ¯ï¼Œè¿‡æ»¤æ‰å·¥å…·æ¶ˆæ¯
                            if self._is_ai_message(msg):
                                content = str(msg.content)

                                # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ï¼ŒåŒºåˆ†æ€è€ƒå’Œå›ç­”
                                message_type = self._classify_ai_message(msg)

                                if message_type == "thinking":
                                    # æ€è€ƒé˜¶æ®µ
                                    if ChatConfig.ENABLE_AI_THINKING_CLASSIFICATION:
                                        formatted_content = f"{ChatConfig.THINKING_EMOJI} {ChatConfig.THINKING_PREFIX}{content}"
                                    else:
                                        formatted_content = content
                                elif message_type == "response":
                                    # æ­£å¼å›ç­”é˜¶æ®µ
                                    if ChatConfig.ENABLE_AI_THINKING_CLASSIFICATION:
                                        formatted_content = f"{ChatConfig.RESPONSE_EMOJI} {ChatConfig.RESPONSE_PREFIX}{content}"
                                    else:
                                        formatted_content = content
                                else:
                                    formatted_content = content

                                # ç®€å•åˆ†å—
                                for i in range(0, len(formatted_content), 30):
                                    yield formatted_content[i : i + 30]
                            return
        except Exception as e:
            logger.error(f"Error in chat_stream: {str(e)}")
            yield f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"

    def _is_ai_message(self, message) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯AIåŠ©æ‰‹çš„æ¶ˆæ¯

        Args:
            message: æ¶ˆæ¯å¯¹è±¡

        Returns:
            bool: æ˜¯å¦æ˜¯AIåŠ©æ‰‹çš„æ¶ˆæ¯
        """
        try:
            # æ£€æŸ¥æ¶ˆæ¯ç±»å‹ - AIåŠ©æ‰‹çš„æ¶ˆæ¯é€šå¸¸æ˜¯AIMessageæˆ–AIMessageChunk
            message_type = type(message).__name__
            if message_type in ["AIMessage", "AIMessageChunk"]:
                return True

            # æ£€æŸ¥æ¶ˆæ¯çš„roleå±æ€§ - AIåŠ©æ‰‹çš„roleé€šå¸¸æ˜¯"assistant"
            if hasattr(message, "role") and message.role == "assistant":
                return True

            # æ£€æŸ¥æ¶ˆæ¯çš„typeå±æ€§ - AIåŠ©æ‰‹çš„typeé€šå¸¸æ˜¯"ai"
            if hasattr(message, "type") and message.type == "ai":
                return True

            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„ç±»å‹ä¿¡æ¯ï¼Œé€šè¿‡æ’é™¤æ³•åˆ¤æ–­
            # æ’é™¤å·¥å…·æ¶ˆæ¯
            if hasattr(message, "tool_call_id"):
                return False

            if hasattr(message, "role") and message.role == "tool":
                return False

            if hasattr(message, "type") and message.type == "tool":
                return False

            if message_type in ["ToolMessage", "ToolMessageChunk"]:
                return False

            # æ’é™¤ç”¨æˆ·æ¶ˆæ¯
            if hasattr(message, "role") and message.role == "user":
                return False

            if hasattr(message, "type") and message.type == "human":
                return False

            if message_type in ["HumanMessage", "HumanMessageChunk"]:
                return False

            # å¦‚æœéƒ½ä¸æ˜¯ï¼Œå¯èƒ½æ˜¯AIæ¶ˆæ¯ï¼Œä¿å®ˆè¾“å‡º
            logger.debug(f"Unknown message type {message_type}, treating as AI message")
            return True

        except Exception as e:
            logger.debug(f"Error checking AI message: {e}")
            return False

    def _classify_ai_message(self, message) -> str:
        """
        åˆ†ç±»AIæ¶ˆæ¯ç±»å‹ï¼šæ€è€ƒ vs å›ç­”

        Args:
            message: AIæ¶ˆæ¯å¯¹è±¡

        Returns:
            str: "thinking" | "response" | "default"
        """
        try:
            # å¦‚æœæœªå¯ç”¨åˆ†ç±»åŠŸèƒ½ï¼Œç›´æ¥è¿”å›é»˜è®¤
            if not ChatConfig.ENABLE_AI_THINKING_CLASSIFICATION:
                return "default"

            # æ£€æŸ¥æ¶ˆæ¯å†…å®¹
            content = str(message.content) if message.content else ""
            if not content.strip():
                return "default"

            # è·å–æ‰€æœ‰æ€è€ƒå’Œå›ç­”æ¨¡å¼çš„å…³é”®è¯
            thinking_patterns = ChatConfig.THINKING_KEYWORDS_ZH + ChatConfig.THINKING_KEYWORDS_EN + ["Action:", "Thought:"]  # ReActæ¨¡å¼çš„ç‰¹æ®Šæ ‡è¯†
            response_patterns = ChatConfig.RESPONSE_KEYWORDS_ZH + ChatConfig.RESPONSE_KEYWORDS_EN

            # ä¼˜å…ˆåŸºäºå†…å®¹ç‰¹å¾åˆ¤æ–­
            # 1. å¦‚æœå†…å®¹åŒ…å«æ€è€ƒæ¨¡å¼å…³é”®è¯ï¼Œå½’ç±»ä¸ºæ€è€ƒ
            if any(pattern in content for pattern in thinking_patterns):
                logger.debug(f"Message classified as thinking based on content patterns")
                return "thinking"

            # 2. å¦‚æœå†…å®¹åŒ…å«å›ç­”æ¨¡å¼å…³é”®è¯ï¼Œå½’ç±»ä¸ºå›ç­”
            if any(pattern in content for pattern in response_patterns):
                logger.debug(f"Message classified as response based on content patterns")
                return "response"

            # 3. æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ä½œä¸ºè¾…åŠ©åˆ¤æ–­
            has_tool_calls = False

            # æ£€æŸ¥tool_callså±æ€§
            if hasattr(message, "tool_calls") and message.tool_calls:
                has_tool_calls = True
                logger.debug(f"Found tool_calls in message: {len(message.tool_calls)} calls")

            # æ£€æŸ¥additional_kwargsä¸­çš„tool_callsï¼ˆOpenAIæ ¼å¼ï¼‰
            if hasattr(message, "additional_kwargs") and message.additional_kwargs:
                if "tool_calls" in message.additional_kwargs and message.additional_kwargs["tool_calls"]:
                    has_tool_calls = True
                    logger.debug(f"Found tool_calls in additional_kwargs")

            # 4. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ä½†æ²¡æœ‰æ˜ç¡®çš„å…³é”®è¯æ¨¡å¼ï¼Œä¹Ÿå€¾å‘äºå½’ç±»ä¸ºæ€è€ƒ
            # å› ä¸ºé€šå¸¸åœ¨è°ƒç”¨å·¥å…·å‰AIä¼šæœ‰æ€è€ƒè¿‡ç¨‹
            if has_tool_calls:
                logger.debug(f"Message classified as thinking due to tool calls")
                return "thinking"

            # 5. é»˜è®¤æƒ…å†µ - æ™®é€šå¯¹è¯
            return "default"

        except Exception as e:
            logger.debug(f"Error classifying AI message: {e}")
            return "default"

    def prepare_config(self, thread_id: Optional[str], session_id: Optional[str]) -> Dict:
        """å‡†å¤‡LangGraphé…ç½®"""
        config = {}
        if thread_id:
            config["configurable"] = {"thread_id": thread_id}
        if session_id:
            config.setdefault("configurable", {})["session_id"] = session_id
        return config
