"""
Agentåè°ƒå™¨ - ç®¡ç†æ€è€ƒAgentå’Œæ‰§è¡ŒAgentçš„åä½œ
å®ç°"æ€è€ƒ-æ‰§è¡Œ"åŒAgentå·¥ä½œæµ
"""

import json
from dataclasses import asdict
from datetime import datetime
from typing import Any, AsyncGenerator, Dict, List, Optional

from copilot.core.execution_agent import ExecutionAgent
from copilot.core.thinking_agent import ThinkingAgent, ThinkingResult
from copilot.utils.logger import logger


class AgentCoordinator:
    """Agentåè°ƒå™¨ - ç®¡ç†æ€è€ƒå’Œæ‰§è¡ŒAgentçš„åä½œ"""

    def __init__(
        self, thinking_agent: ThinkingAgent, execution_agent: ExecutionAgent, enable_thinking_mode: bool = True, save_thinking_process: bool = True
    ):
        """
        åˆå§‹åŒ–åè°ƒå™¨

        Args:
            thinking_agent: æ€è€ƒAgentå®ä¾‹
            execution_agent: æ‰§è¡ŒAgentå®ä¾‹
            enable_thinking_mode: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
            save_thinking_process: æ˜¯å¦ä¿å­˜æ€è€ƒè¿‡ç¨‹
        """
        self.thinking_agent = thinking_agent
        self.execution_agent = execution_agent
        self.enable_thinking_mode = enable_thinking_mode
        self.save_thinking_process = save_thinking_process

        # æ€è€ƒè¿‡ç¨‹å­˜å‚¨
        self.thinking_history: Dict[str, List[ThinkingResult]] = {}

        logger.info(f"AgentCoordinator initialized with thinking_mode={enable_thinking_mode}")

    async def process_user_input(
        self,
        user_input: str,
        session_id: str,
        thread_id: Optional[str] = None,
        images: Optional[List] = None,
        enable_tools: bool = True,
        context: Dict[str, Any] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œåè°ƒæ€è€ƒå’Œæ‰§è¡Œè¿‡ç¨‹

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            thread_id: çº¿ç¨‹ID
            images: å›¾ç‰‡åˆ—è¡¨
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Yields:
            Dict[str, Any]: æµå¼å“åº”æ•°æ®
        """
        try:
            # å¦‚æœå¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œå…ˆè¿›è¡Œæ€è€ƒ
            if self.enable_thinking_mode:
                async for chunk in self._process_with_thinking(user_input, session_id, thread_id, images, enable_tools, context):
                    yield chunk
            else:
                # ç›´æ¥æ‰§è¡Œæ¨¡å¼
                async for chunk in self._process_direct_execution(user_input, session_id, thread_id, images, enable_tools):
                    yield chunk

        except Exception as e:
            logger.error(f"AgentCoordinatorå¤„ç†å‡ºé”™: {str(e)}")
            yield {"type": "error", "content": f"åè°ƒå™¨å¤„ç†å‡ºé”™: {str(e)}", "timestamp": datetime.now().isoformat()}

    async def _process_with_thinking(
        self, user_input: str, session_id: str, thread_id: Optional[str], images: Optional[List], enable_tools: bool, context: Dict[str, Any]
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """å¸¦æ€è€ƒçš„å¤„ç†æµç¨‹"""

        # 1. å¼€å§‹æ€è€ƒé˜¶æ®µ
        yield {"type": "thinking_start", "content": "ğŸ¤” æ­£åœ¨åˆ†ææ‚¨çš„éœ€æ±‚...", "phase": "thinking", "timestamp": datetime.now().isoformat()}

        try:
            # 2. è·å–å¯¹è¯å†å²ç”¨äºæ€è€ƒ
            conversation_history = await self._get_conversation_history(session_id)

            # 3. æ€è€ƒAgentåˆ†æ
            thinking_result = await self.thinking_agent.think(user_input=user_input, context=context, conversation_history=conversation_history)

            # 4. ä¿å­˜æ€è€ƒè¿‡ç¨‹
            if self.save_thinking_process:
                self._save_thinking_result(session_id, thinking_result)

            # 5. è¾“å‡ºæ€è€ƒç»“æœ
            yield {
                "type": "thinking_result",
                "content": self._format_thinking_result(thinking_result),
                "thinking_data": asdict(thinking_result),
                "phase": "thinking",
                "timestamp": datetime.now().isoformat(),
            }

            # 6. å¼€å§‹æ‰§è¡Œé˜¶æ®µ
            yield {
                "type": "execution_start",
                "content": "âš¡ å¼€å§‹æ‰§è¡Œä»»åŠ¡...",
                "phase": "execution",
                "execution_plan": [asdict(step) for step in thinking_result.execution_plan],
                "timestamp": datetime.now().isoformat(),
            }

            # 7. æ„å»ºå¢å¼ºçš„æ‰§è¡Œè¾“å…¥
            enhanced_input = self._build_enhanced_input(user_input, thinking_result)

            # 8. æ‰§è¡ŒAgentå¤„ç†
            async for chunk in self.execution_agent.chat(
                message=enhanced_input, thread_id=thread_id, session_id=session_id, images=images, enable_tools=enable_tools
            ):
                # ä¸ºæ‰§è¡Œé˜¶æ®µçš„è¾“å‡ºæ·»åŠ æ ‡è¯†
                if isinstance(chunk, dict):
                    chunk["phase"] = "execution"
                    yield chunk
                else:
                    yield {"type": "content", "content": chunk, "phase": "execution", "timestamp": datetime.now().isoformat()}

            # 9. æ‰§è¡Œå®Œæˆ
            yield {"type": "execution_complete", "content": "âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ", "phase": "complete", "timestamp": datetime.now().isoformat()}

        except Exception as e:
            logger.error(f"æ€è€ƒ-æ‰§è¡Œæµç¨‹å‡ºé”™: {str(e)}")
            yield {"type": "error", "content": f"æ€è€ƒæˆ–æ‰§è¡Œè¿‡ç¨‹å‡ºé”™: {str(e)}", "phase": "error", "timestamp": datetime.now().isoformat()}

    async def _process_direct_execution(
        self, user_input: str, session_id: str, thread_id: Optional[str], images: Optional[List], enable_tools: bool
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """ç›´æ¥æ‰§è¡Œæ¨¡å¼"""

        yield {"type": "execution_start", "content": "ç›´æ¥å¤„ç†æ‚¨çš„è¯·æ±‚...", "phase": "execution", "timestamp": datetime.now().isoformat()}

        async for chunk in self.execution_agent.chat(
            message=user_input, thread_id=thread_id, session_id=session_id, images=images, enable_tools=enable_tools
        ):
            if isinstance(chunk, dict):
                chunk["phase"] = "execution"
                yield chunk
            else:
                yield {"type": "content", "content": chunk, "phase": "execution", "timestamp": datetime.now().isoformat()}

    def _format_thinking_result(self, result: ThinkingResult) -> str:
        """æ ¼å¼åŒ–æ€è€ƒç»“æœä¸ºç”¨æˆ·å¯è¯»çš„æ–‡æœ¬"""
        formatted_text = f"""ğŸ’­ **åˆ†æç»“æœ**

**ç”¨æˆ·æ„å›¾**: {result.user_intent}

**é—®é¢˜åˆ†æ**: {result.problem_analysis}

**æ‰§è¡Œè®¡åˆ’**:
"""

        for i, step in enumerate(result.execution_plan, 1):
            formatted_text += f"\n{i}. **{step.description}**"
            formatted_text += f"\n   - åŸå› : {step.reasoning}"
            if step.expected_tools:
                formatted_text += f"\n   - é¢„æœŸå·¥å…·: {', '.join(step.expected_tools)}"
            if step.dependencies:
                formatted_text += f"\n   - ä¾èµ–: {', '.join(step.dependencies)}"

        formatted_text += f"\n\n**å¤æ‚åº¦è¯„ä¼°**: {result.estimated_complexity}"

        if result.suggested_model:
            formatted_text += f"\n**å»ºè®®æ¨¡å‹**: {result.suggested_model}"

        return formatted_text

    def _build_enhanced_input(self, original_input: str, thinking_result: ThinkingResult) -> str:
        """æ„å»ºå¢å¼ºçš„æ‰§è¡Œè¾“å…¥ï¼ŒåŒ…å«æ€è€ƒç»“æœ"""

        enhanced_input = f"""ç”¨æˆ·åŸå§‹è¾“å…¥: {original_input}

åŸºäºæ·±åº¦åˆ†æï¼Œæˆ‘éœ€è¦æŒ‰ä»¥ä¸‹è®¡åˆ’æ‰§è¡Œ:

ç”¨æˆ·æ„å›¾: {thinking_result.user_intent}
é—®é¢˜åˆ†æ: {thinking_result.problem_analysis}

æ‰§è¡Œæ­¥éª¤:
"""

        for i, step in enumerate(thinking_result.execution_plan, 1):
            enhanced_input += f"\n{i}. {step.description}"
            enhanced_input += f"\n   åŸå› : {step.reasoning}"
            if step.expected_tools:
                enhanced_input += f"\n   éœ€è¦å·¥å…·: {', '.join(step.expected_tools)}"
            if step.parameters:
                enhanced_input += f"\n   å‚æ•°: {json.dumps(step.parameters, ensure_ascii=False)}"

        enhanced_input += "\n\nè¯·æŒ‰ç…§è¿™ä¸ªè®¡åˆ’æ‰§è¡Œï¼Œç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½å¾—åˆ°é€‚å½“çš„å¤„ç†ã€‚"

        return enhanced_input

    async def _get_conversation_history(self, session_id: str) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        try:
            # ä»æ‰§è¡ŒAgentçš„å†å²ç®¡ç†å™¨è·å–å†å²è®°å½•
            if hasattr(self.execution_agent, "chat_history_manager"):
                history_messages = await self.execution_agent.chat_history_manager.get_session_messages(session_id=session_id, limit=10)

                # è½¬æ¢ä¸ºç®€å•çš„å­—å…¸æ ¼å¼
                conversation_history = []
                for msg in history_messages:
                    conversation_history.append(
                        {"role": msg.role, "content": msg.content, "timestamp": msg.timestamp.isoformat() if msg.timestamp else None}
                    )

                return conversation_history

        except Exception as e:
            logger.warning(f"è·å–å¯¹è¯å†å²å¤±è´¥: {str(e)}")

        return []

    def _save_thinking_result(self, session_id: str, result: ThinkingResult):
        """ä¿å­˜æ€è€ƒç»“æœ"""
        if session_id not in self.thinking_history:
            self.thinking_history[session_id] = []

        self.thinking_history[session_id].append(result)

        # åªä¿ç•™æœ€è¿‘20æ¬¡æ€è€ƒè®°å½•
        if len(self.thinking_history[session_id]) > 20:
            self.thinking_history[session_id] = self.thinking_history[session_id][-20:]

    def get_thinking_history(self, session_id: str) -> List[ThinkingResult]:
        """è·å–ä¼šè¯çš„æ€è€ƒå†å²"""
        return self.thinking_history.get(session_id, [])

    def clear_thinking_history(self, session_id: str):
        """æ¸…é™¤ä¼šè¯çš„æ€è€ƒå†å²"""
        if session_id in self.thinking_history:
            del self.thinking_history[session_id]

    def configure_thinking_mode(self, enabled: bool):
        """é…ç½®æ€è€ƒæ¨¡å¼"""
        self.enable_thinking_mode = enabled
        logger.info(f"Thinking mode set to: {enabled}")

    def get_coordinator_stats(self) -> Dict[str, Any]:
        """è·å–åè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯"""
        total_thinking_sessions = len(self.thinking_history)
        total_thinking_records = sum(len(history) for history in self.thinking_history.values())

        return {
            "thinking_mode_enabled": self.enable_thinking_mode,
            "save_thinking_process": self.save_thinking_process,
            "total_thinking_sessions": total_thinking_sessions,
            "total_thinking_records": total_thinking_records,
            "thinking_agent_stats": self.thinking_agent.get_thinking_stats(),
            "execution_agent_info": {
                "provider": self.execution_agent.provider,
                "model": self.execution_agent.model_name,
                "context_memory_enabled": getattr(self.execution_agent, "context_memory_enabled", False),
            },
        }

    async def refine_and_retry(
        self,
        session_id: str,
        feedback: str,
        original_input: str,
        thread_id: Optional[str] = None,
        images: Optional[List] = None,
        enable_tools: bool = True,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æ ¹æ®åé¦ˆä¼˜åŒ–è®¡åˆ’å¹¶é‡è¯•æ‰§è¡Œ

        Args:
            session_id: ä¼šè¯ID
            feedback: ç”¨æˆ·åé¦ˆæˆ–é”™è¯¯ä¿¡æ¯
            original_input: åŸå§‹ç”¨æˆ·è¾“å…¥
            thread_id: çº¿ç¨‹ID
            images: å›¾ç‰‡åˆ—è¡¨
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·

        Yields:
            Dict[str, Any]: æµå¼å“åº”æ•°æ®
        """
        try:
            # è·å–æœ€è¿‘çš„æ€è€ƒç»“æœ
            thinking_history = self.get_thinking_history(session_id)
            if not thinking_history:
                yield {"type": "error", "content": "æ²¡æœ‰æ‰¾åˆ°ä¹‹å‰çš„æ€è€ƒè®°å½•ï¼Œæ— æ³•ä¼˜åŒ–", "timestamp": datetime.now().isoformat()}
                return

            last_thinking = thinking_history[-1]

            # ä¼˜åŒ–è®¡åˆ’
            yield {
                "type": "refining_start",
                "content": "ğŸ”„ æ­£åœ¨æ ¹æ®åé¦ˆä¼˜åŒ–æ‰§è¡Œè®¡åˆ’...",
                "phase": "refining",
                "timestamp": datetime.now().isoformat(),
            }

            refined_result = await self.thinking_agent.refine_plan(last_thinking, feedback)

            # ä¿å­˜ä¼˜åŒ–åçš„è®¡åˆ’
            if self.save_thinking_process:
                self._save_thinking_result(session_id, refined_result)

            # è¾“å‡ºä¼˜åŒ–ç»“æœ
            yield {
                "type": "refined_plan",
                "content": f"ğŸ“‹ ä¼˜åŒ–åçš„æ‰§è¡Œè®¡åˆ’:\n{self._format_thinking_result(refined_result)}",
                "thinking_data": asdict(refined_result),
                "phase": "refining",
                "timestamp": datetime.now().isoformat(),
            }

            # é‡æ–°æ‰§è¡Œ
            yield {
                "type": "retry_execution_start",
                "content": "ğŸ”„ å¼€å§‹é‡æ–°æ‰§è¡Œ...",
                "phase": "retry_execution",
                "timestamp": datetime.now().isoformat(),
            }

            enhanced_input = self._build_enhanced_input(original_input, refined_result)

            async for chunk in self.execution_agent.chat(
                message=enhanced_input, thread_id=thread_id, session_id=session_id, images=images, enable_tools=enable_tools
            ):
                if isinstance(chunk, dict):
                    chunk["phase"] = "retry_execution"
                    yield chunk
                else:
                    yield {"type": "content", "content": chunk, "phase": "retry_execution", "timestamp": datetime.now().isoformat()}

        except Exception as e:
            logger.error(f"ä¼˜åŒ–é‡è¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
            yield {"type": "error", "content": f"ä¼˜åŒ–é‡è¯•è¿‡ç¨‹å‡ºé”™: {str(e)}", "timestamp": datetime.now().isoformat()}
